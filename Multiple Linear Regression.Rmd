---
title: "Week 3: Project"
author: "Joel Konitzer"
date: '2022-07-19'
output:
  pdf_document: default
  html_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# load the data.table, ggolot2, and dplyr libraries
library('ggplot2')
library('dplyr')
library('stargazer')
library('car')
```

#### Introduction 

This project aims to demonstrate and develop a multilinear regression model. A multilinear regressions goal is to develop a linear relationship between independent and dependent variables to estimate the response of the dependent variable based on the change of an independent variable. A multilinear regression model's value depends on various factors, including subject matter knowledge, testing time, and general data quality. The data analyzed for this project is an aggregate of weekly revenue, cost, and various IT operations metrics I queried from my employer's SQL database. Since this is a time-series dataset with only numeric values, it is ideal for regression analysis. The dependent variable is revenue to predict weekly amounts from weekly operations data.
```{r}
# Load data
dt <- read.csv("data_week3.csv")
```

```{r}
# EDA ---------------------------------------------------------------------
# Check the structure
dim(dt)
str(dt)

#Drop record_date column
dt <- dt[-c(1)]

#View summary statistics, value distribution, and outlier detection
summary(dt)
hist(dt$ttl_revenue, main = "Revenue value distribution")
plot(density(dt$ttl_revenue,na.rm=TRUE), main = "Revenue value distribution")
boxplot(dt$ttl_revenue, main = "Revenue: with outliers")

# Remove the outliers from Revenue
# Select upper & lower quartiles to assign as outliers
quartiles <- quantile(dt$ttl_revenue, probs=c(.25, .75), na.rm = FALSE)
IQR <- IQR(dt$ttl_revenue, na.rm = TRUE)
Lower <- quartiles[1] - 1.5*IQR
Upper <- quartiles[2] + 1.5*IQR
dt_clean <- subset(dt, dt$ttl_revenue > Lower & dt$ttl_revenue < Upper)
dt_clean <- dt_clean[dt$ttl_revenue > 0, ]

#Remove NAs
dt_clean <- dt_clean[complete.cases(dt_clean),]
dim(dt_clean)

#Confirm outliers were removed
#Outliers are still present, but lets see how the regression turns out
boxplot(dt_clean$ttl_revenue, main = "Revenue: outliers removed")

#View data shape after removing outliers & calculate amount removed
dim(dt_clean)
outliers_removed <- nrow(dt) - nrow(dt_clean)
outliers_removed
```

#### Methods 

The dataset features were analyzed using native R functions and multiple regression literature to assess model performance. Outlier effects can significantly influence model performance, so outliers were removed from the Revenue column using the IQR zone as a reference, illustrated in the boxplots below. Any non-integer values were also removed from the dataset as they cause R to throw an error upon code execution. One regression was performed using highly correlated features based on results from a correlation matrix generated by the Corrplot() function from the Corrplot library. Native R functions were used to analyze the regression results listed at the beginning of this analysis and before code executions. 

```{r}
# View Correlations -------------------------------------------------------
# Plot a correlation matrix
par(mfrow=c(1,1))
library(corrplot)
corrplot(cor(dt_clean), method='number')
```   
#### Results
The results from the correlation plot showed ttl_cost and avg_hours_actual to be the most positively correlated with ttl_revenue, while ttl_company_count and ttl_ticket_count are the lowest. The assumption plots from the model ran on all features appear to follow a normal distribution; however, looking at the Residuals vs. Leverage plot, we see that additional outlier removal may be needed. The summary results align with the corrplot results above; ttl_cost and avg_hours_actual appear to provide the most explanatory value. The VIF value for time_entry is comparatively high, indicating colinearity may exist. The second regression was run using only ttl_cost, avg_hours_actual, which returned a lower AIC score than the regression with all features. A lower AIC score indicates a better-performing model as it estimates prediction error. Automatic feature selection was tested using the StepAIC function, which analyzes dataset features to find optimal combinations for regression analysis. The results showed that a better AIC score is achieved by removing ttl_company_count and running the regression with the remaining features. 
	
```{r}
# Run regression ----------------------------------------------------------
### Linear Model ###
# Fit linear model to quality and all variables
fit <- lm(ttl_revenue ~ ., data = dt_clean)
summary(fit)
plot(fit)

## Check Assumptions ## 
# View the summary, VIF, and residual plots of the fit
vif(fit)
AIC(fit)
```   



```{r}

# Created reduced model -------------------------------------------------------

dt_reduced <- dt_clean
columns_new <- c('ttl_revenue','ttl_cost','avg_hours_actual')
dt_reduced <- subset(dt_reduced, select = columns_new)


newfit <- lm(ttl_revenue ~ ttl_cost + avg_hours_actual, data = dt_reduced)
summary(newfit)
plot(newfit)
AIC(newfit)

library(MASS)
stepAIC(newfit, direction = 'both')
stepAIC(fit, direction = 'both')
``` 

#### Conclusion

This analysis shows that weekly revenue amounts are explained more by average hours worked than total companies invoiced. Multiple regression can be employed for various purposes but understanding how to conduct the analysis properly is essential. The EDA steps showed that using the IQR method may not always be effective in removing all desired outliers, and using the corrplot is a practical feature selection method. Itâ€™s important to note that results may have been different if only average aggregates were used, but instead, the dataset used had a variation of summations and averaging.  

